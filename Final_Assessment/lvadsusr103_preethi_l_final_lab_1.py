# -*- coding: utf-8 -*-
"""LVADSUSR103_Preethi_L_Final_lab_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zzQZ1dIhUDYKNwkbkioY3rdIDRnCJzX_
"""

from google.colab import drive
drive.mount('/content/drive')

#1
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score,f1_score,mean_squared_error,r2_score,classification_report,confusion_matrix

data = pd.read_csv("/content/drive/MyDrive/loan_approval.csv")
data

# rows and columns
data.shape

data.isnull().sum()

data.info()

data.describe()

data.head(10)

data.duplicated().sum()

#outliers
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
thershold = 1.5
#interquartile range
IQR = Q3-Q1
outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)
print(outliers)

data1 = data[~outliers]

data1.info()

data1.shape

data1.head(10)

data.corr()

#pictorial view of numerical values
num_cols = [' income_annum', ' loan_amount', ' cibil_score', ' residential_assets_value', ' commercial_assets_value', ' luxury_assets_value', ' bank_asset_value']
data[num_cols].hist(figsize=(14, 9))
plt.suptitle('Histogram view of Numerical Features in Loan Data')
plt.show()

# giving the pictorial view of Categorical columns
categorical_cols = [' education', ' self_employed']
plt.figure(figsize=(12, 6))
for j, cols in enumerate(categorical_cols, 1):
    plt.subplot(1, 2, j)
    sns.countplot(x=cols, data=data,color = 'gray')
    plt.title(f'Distribution of {cols}!')
plt.tight_layout()
plt.show()

# countplot using seaborn library
plt.figure(figsize=(12, 6))
for i, cols in enumerate(categorical_cols, 1):
    plt.subplot(1, 2, i)
    sns.countplot(x=cols, hue=' loan_status', data=data1)
    plt.title('Relationship between {} and Loan Approval Status!'.format(cols))
plt.tight_layout()
plt.legend()
plt.show()

# to see how the features are plotted in box plot
plt.figure(figsize=(11, 7))
for i, col in enumerate(num_cols, 1):
    plt.subplot(2, 4, i)
    sns.boxplot(x=' loan_status', y=col, data=data1,color = 'gray')
plt.tight_layout()
plt.suptitle("Box plot for numerical Columns\n\n")
plt.show()

df = pd.get_dummies(data1, columns=[' education', ' self_employed'])
data.head(14)

# dropping the  loan_status feature as it is to be checked
X = df.drop(columns=[' loan_status'])
y = df[' loan_status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

df.describe()

#using random forest classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train_scaled, y_train)

# here we're predicting the data using and found some of the metrics of classification
y_pred = rf_classifier.predict(X_test_scaled)
acc_score = accuracy_score(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
con_matrix = confusion_matrix(y_test, y_pred)
print("Accuracy score is : ", acc_score,"\n")
print("Classification Report of Loan Approval status is : \n",class_report)
print("Confusion Matrix of Loan Approval data is : \n",con_matrix)