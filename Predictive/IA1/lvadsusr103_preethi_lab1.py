# -*- coding: utf-8 -*-
"""LVADSUSR103_Preethi_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fQCaW52zxPRx0TxHKdGl73lWSxF4OZdh
"""

#Expenses Dataset
#importing libraries

import pandas as pd
import numpy as np
import warnings as wr
wr.filterwarnings("ignore")

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,r2_score



#1
# checking for missing values
data_1 = pd.read_csv("/content/drive/MyDrive/expenses.csv")
#getting information bout the dataset
data_1.info()

# finding any null values
print(data_1.isnull().sum())
#there is no null values as the output itself tells about this

# finding any duplicates
data = data_1.drop_duplicates()

#outliers detection
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
#InterQuartile Range
IQR = Q3 - Q1
threshold_value = 1.5
Outliers = (data < (Q1 - threshold_value * IQR)) | (data  > (Q3 + threshold_value * IQR))
data_file = data[~Outliers.any(axis=1)]

# droping the unnecessary columns
data_cleaning = data.drop(['children'], axis=1)
data_cleaning.head()


# encoding the categorical columns using Label Encoding method
label_encoder = LabelEncoder()
data_cleaning['sex'] = label_encoder.fit_transform(data_cleaning['sex'])
data_cleaning['smoker'] = label_encoder.fit_transform(data_cleaning['smoker'])
data_cleaning['region'] = label_encoder.fit_transform(data_cleaning['region'])

X=


# Splitting the Data into Train and Test Sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model building using Logistic Regression
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)